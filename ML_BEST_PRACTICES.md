# ğŸ›¡ï¸ Machine Learning Best Practices - Anti-Leakage & Drift Prevention

## ğŸ“š Documento de Referencia para Proyectos de ML

Este documento describe las **4 mejoras crÃ­ticas** implementadas en el notebook `train.ipynb` para prevenir problemas comunes en Machine Learning.

---

## 1ï¸âƒ£ DATA LEAKAGE PREVENTION

### âŒ Problema
El modelo "ve" informaciÃ³n del conjunto de test durante el entrenamiento, inflando artificialmente las mÃ©tricas.

### ğŸ” Ejemplos de Data Leakage

**Caso 1: NormalizaciÃ³n incorrecta**
```python
# âŒ MAL - Fit del scaler con TODOS los datos
scaler.fit(X)  # Incluye train, val y test
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**Caso 2: Features derivadas del target**
```python
# âŒ MAL - Feature que "conoce" el resultado
df['is_fraud_ratio'] = df.groupby('user_id')['is_fraud'].transform('mean')
# Esta feature contiene informaciÃ³n del target!
```

### âœ… SoluciÃ³n Implementada

```python
# âœ… BIEN - Scaler se entrena SOLO con training
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Aprende de training
X_val_scaled = scaler.transform(X_val)          # Solo transforma
X_test_scaled = scaler.transform(X_test)        # Solo transforma
```

### ğŸ” Validaciones Implementadas

1. **VerificaciÃ³n de overlap**: Asegurar que no hay filas duplicadas entre train/val/test
2. **AnÃ¡lisis de correlaciones**: Detectar features con correlaciÃ³n >0.95 con el target
3. **ValidaciÃ³n de varianza**: Identificar features sin informaciÃ³n Ãºtil

---

## 2ï¸âƒ£ TEST CONTAMINATION PREVENTION

### âŒ Problema
Usar el conjunto de test para ajustar hiperparÃ¡metros contamina la evaluaciÃ³n final.

### ğŸ” Ejemplo de ContaminaciÃ³n

```python
# âŒ MAL - Tunear hiperparÃ¡metros con test
for n_estimators in [50, 100, 200]:
    model = RandomForest(n_estimators=n_estimators)
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)  # âš ï¸ Usando test para decidir!
    if score > best_score:
        best_n_estimators = n_estimators
```

### âœ… SoluciÃ³n: DivisiÃ³n en 3 Conjuntos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dataset Total (100%)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  Train (70%)  â†’  Entrenar modelo        â”‚
â”‚                                         â”‚
â”‚  Val (15%)    â†’  Ajustar hiperparÃ¡metrosâ”‚
â”‚                  Validar durante dev    â”‚
â”‚                                         â”‚
â”‚  Test (15%)   â†’  EvaluaciÃ³n FINAL       â”‚
â”‚                  (tocar UNA VEZ)        â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š ImplementaciÃ³n

```python
# DivisiÃ³n estratificada en 3 conjuntos
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp
)
```

### ğŸ¯ Workflow Correcto

1. **Durante desarrollo**:
   - Entrenar con `X_train, y_train`
   - Evaluar con `X_val, y_val`
   - Iterar ajustando hiperparÃ¡metros basÃ¡ndote en validation

2. **Al final (UNA VEZ)**:
   - Evaluar con `X_test, y_test`
   - Reportar mÃ©tricas finales
   - NO iterar mÃ¡s despuÃ©s de ver test

### ğŸ”„ Alternativa: Nested Cross-Validation

Para datasets pequeÃ±os (<10k samples):

```python
from sklearn.model_selection import cross_val_score, GridSearchCV

# CV externa: evaluar el modelo
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)

# CV interna: tunear hiperparÃ¡metros
inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)

clf = GridSearchCV(
    estimator=RandomForestClassifier(),
    param_grid={'n_estimators': [50, 100, 200]},
    cv=inner_cv
)

scores = cross_val_score(clf, X, y, cv=outer_cv)
```

---

## 3ï¸âƒ£ DATA DRIFT / CONCEPT DRIFT DETECTION

### âŒ Problema
Los datos cambian con el tiempo y el modelo se vuelve obsoleto sin que lo notes.

### ğŸ” Tipos de Drift

**Data Drift**: La distribuciÃ³n de las features cambia
```
Training (2024):    avg_url_length = 45 caracteres
Production (2025):  avg_url_length = 120 caracteres  âš ï¸ CambiÃ³!
```

**Concept Drift**: La relaciÃ³n featureâ†’target cambia
```
Antes:  "bit.ly" â†’ 80% phishing
Ahora:  "bit.ly" â†’ 30% phishing (acortadores mÃ¡s seguros)
```

### âœ… SoluciÃ³n: Monitoreo Continuo

#### 1. Guardar Baseline en Training

```python
baseline_stats = {
    'feature_statistics': {
        'url_length': {
            'mean': 45.2,
            'std': 12.8,
            'min': 10,
            'max': 200
        }
    },
    'performance_baseline': {
        'test_accuracy': 0.9523,
        'test_f1': 0.9481
    }
}
```

#### 2. Detectar Drift en ProducciÃ³n

```python
from scipy.stats import ks_2samp

def check_drift(new_data, baseline, threshold=0.05):
    """
    Detecta drift usando test de Kolmogorov-Smirnov
    
    Returns:
        drift_detected: bool
        features_with_drift: list
    """
    drift_features = []
    
    for feature in baseline['feature_statistics'].keys():
        # KS test: compara distribuciones
        ks_stat, p_value = ks_2samp(
            baseline_samples[feature],  # Samples de training
            new_data[feature]           # Samples de producciÃ³n
        )
        
        # Si p < 0.05 â†’ distribuciones son diferentes
        if p_value < threshold:
            drift_features.append(feature)
    
    return len(drift_features) > 0, drift_features
```

#### 3. Detectar Performance Decay

```python
# Monitorear accuracy en producciÃ³n (requiere ground truth)
current_accuracy = evaluate_production_data(model, labeled_production_data)

if current_accuracy < baseline_stats['test_accuracy'] * 0.90:
    print("âš ï¸ Accuracy cayÃ³ >10% - Necesita re-entrenamiento")
```

### ğŸ“… Estrategia de Re-entrenamiento

| SeÃ±al | AcciÃ³n |
|-------|--------|
| Drift leve (1-2 features) | Monitorear |
| Drift moderado (3-5 features) | Planear re-entrenamiento |
| Drift severo (>5 features) | Re-entrenar inmediatamente |
| Accuracy cae >10% | Re-entrenar urgente |

### ğŸ”„ Ciclo de Vida del Modelo

```
1. Training inicial     â†’ Baseline guardado
2. Deploy a producciÃ³n  â†’ Monitoreo activo
3. Drift detectado      â†’ Alerta generada
4. Re-training          â†’ Nuevo baseline
5. A/B testing          â†’ Validar mejora
6. Deploy nueva versiÃ³n â†’ Volver a paso 2
```

---

## 4ï¸âƒ£ HIDDEN FEATURE LEAKAGE DETECTION

### âŒ Problema
Una feature contiene informaciÃ³n del target sin que lo sepas, el modelo "hace trampa".

### ğŸ” Ejemplos Reales

**Caso 1: Competencia Kaggle (NeumonÃ­a en rayos X)**
```
Feature: "image_filename"
PatrÃ³n descubierto: "pneumonia_patient_123.jpg"

Accuracy aparente: 99.9%
Accuracy real: 55%

âŒ El modelo aprendiÃ³ a leer el nombre del archivo, no la imagen!
```

**Caso 2: PredicciÃ³n de Fraude**
```python
# âŒ Feature leaky
df['transaction_declined'] = ...  # Esta columna viene DESPUÃ‰S del fraude
                                  # El modelo no tendrÃ¡ este dato en producciÃ³n!
```

**Caso 3: Features Temporales**
```python
# âŒ Usando informaciÃ³n del futuro
df['avg_next_week_purchases'] = ...  # No existe al momento de predecir
```

### âœ… SoluciÃ³n: AnÃ¡lisis de CorrelaciÃ³n

#### 1. Detectar Features Sospechosas

```python
from scipy.stats import pearsonr

for feature in FEATURES:
    corr, p_value = pearsonr(X_train[feature], y_train)
    
    if abs(corr) > 0.95:
        print(f"ğŸš¨ {feature}: correlaciÃ³n {corr:.4f} - SOSPECHOSO!")
    elif abs(corr) > 0.80:
        print(f"âš ï¸ {feature}: correlaciÃ³n {corr:.4f} - Revisar")
```

#### 2. Validar con Conocimiento del Dominio

Preguntas clave:
- âœ… Â¿Esta feature estarÃ¡ disponible en producciÃ³n?
- âœ… Â¿La feature es anterior al evento que quiero predecir?
- âœ… Â¿La feature es calculable sin conocer el target?

#### 3. Feature Importance Sanity Check

```python
# Si una feature tiene >90% de importancia â†’ sospechoso
feature_importance = model.feature_importances_

for i, (feat, imp) in enumerate(zip(FEATURES, feature_importance)):
    if imp > 0.90:
        print(f"ğŸš¨ {feat} tiene {imp:.2%} de importancia - Investigar!")
```

### ğŸ¯ Checklist de ValidaciÃ³n

- [ ] Â¿La feature existirÃ¡ en el momento de la predicciÃ³n?
- [ ] Â¿La feature es calculable sin conocer el outcome?
- [ ] Â¿La correlaciÃ³n con target es <0.80?
- [ ] Â¿Tiene sentido lÃ³gico que esta feature prediga el target?
- [ ] Â¿El rendimiento es "demasiado bueno para ser verdad"?

---

## ğŸ“ RESUMEN: Flujo de Trabajo Correcto

### ğŸ“‹ Pipeline Completo

```python
# 1ï¸âƒ£ Cargar datos
df = load_data()

# 2ï¸âƒ£ ANTES de dividir: limpieza bÃ¡sica
df = df.drop_duplicates()
df = df.dropna()

# 3ï¸âƒ£ Separar features y target
X = df[FEATURES]
y = df['target']

# 4ï¸âƒ£ DivisiÃ³n estratificada (70/15/15)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.30, stratify=y, random_state=42
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42
)

# 5ï¸âƒ£ NormalizaciÃ³n SOLO con training
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# 6ï¸âƒ£ Validaciones anti-leakage
check_data_overlap(X_train, X_val, X_test)
check_feature_leakage(X_train, y_train)
check_data_drift(X_train, X_test)

# 7ï¸âƒ£ Entrenar modelo
model = RandomForestClassifier()
model.fit(X_train_scaled, y_train)

# 8ï¸âƒ£ Evaluar en VALIDATION (para tunear)
y_val_pred = model.predict(X_val_scaled)
val_score = f1_score(y_val, y_val_pred)
print(f"Validation F1: {val_score}")

# 9ï¸âƒ£ Ajustar hiperparÃ¡metros basÃ¡ndote en validation
# ... iterar pasos 7-8 ...

# ğŸ”Ÿ EvaluaciÃ³n FINAL en test (UNA VEZ)
y_test_pred = model.predict(X_test_scaled)
test_score = f1_score(y_test, y_test_pred)
print(f"Test F1: {test_score}")

# 1ï¸âƒ£1ï¸âƒ£ Guardar baseline para monitoreo
save_baseline_stats(X_train, y_train, test_score)

# 1ï¸âƒ£2ï¸âƒ£ Deploy y monitoreo continuo
monitor_drift_in_production()
```

---

## ğŸ“š Referencias y Recursos

### ğŸ“– Lecturas Recomendadas

1. **[Google - Rules of Machine Learning](https://developers.google.com/machine-learning/guides/rules-of-ml)**
   - Rule #6: Be careful about leaked information from data collection

2. **[Kaggle - Data Leakage](https://www.kaggle.com/learn/data-leakage)**
   - Tutorial interactivo sobre leakage

3. **[Towards Data Science - Concept Drift](https://towardsdatascience.com/machine-learning-in-production-why-you-should-care-about-data-and-concept-drift-d96d0bc907fb)**
   - DetecciÃ³n y manejo de drift

4. **[Papers with Code - Distribution Shift](https://paperswithcode.com/task/domain-adaptation)**
   - Estado del arte en domain adaptation

### ğŸ› ï¸ Herramientas Ãštiles

| Tool | PropÃ³sito |
|------|-----------|
| [Evidently AI](https://github.com/evidentlyai/evidently) | Monitoreo de drift en producciÃ³n |
| [Great Expectations](https://greatexpectations.io/) | ValidaciÃ³n de calidad de datos |
| [MLflow](https://mlflow.org/) | Tracking de experimentos y versiones |
| [Weights & Biases](https://wandb.ai/) | Monitoreo de modelos en producciÃ³n |

### âš™ï¸ ConfiguraciÃ³n de Monitoreo

```python
# IntegraciÃ³n con Evidently AI para drift detection
from evidently.dashboard import Dashboard
from evidently.tabs import DataDriftTab

dashboard = Dashboard(tabs=[DataDriftTab()])
dashboard.calculate(reference_data=X_train, current_data=X_production)
dashboard.save("drift_report.html")
```

---

## âœ… Checklist Final

Antes de deployar tu modelo, verifica:

### Pre-Training
- [ ] Features no contienen informaciÃ³n del futuro
- [ ] No hay features derivadas del target
- [ ] Dataset libre de duplicados
- [ ] DivisiÃ³n estratificada correcta (70/15/15)

### During Training
- [ ] Scaler/encoder entrenado solo con training
- [ ] HiperparÃ¡metros ajustados con validation
- [ ] Test set NO tocado durante desarrollo

### Post-Training
- [ ] Validaciones anti-leakage ejecutadas
- [ ] AnÃ¡lisis de drift completado
- [ ] Correlaciones de features verificadas
- [ ] Baseline statistics guardadas

### Production
- [ ] Sistema de monitoreo de drift configurado
- [ ] Alertas de performance decay activas
- [ ] Plan de re-entrenamiento definido
- [ ] A/B testing strategy para nuevas versiones

---

## ğŸ¯ ConclusiÃ³n

Los 4 problemas cubiertos (Data Leakage, Test Contamination, Drift, Hidden Leakage) son **responsables del 80% de los fallos de modelos en producciÃ³n**.

Implementar estas validaciones **antes** de deployar puede ahorrar:
- âŒ Meses de trabajo de debugging
- âŒ PÃ©rdida de confianza del usuario
- âŒ Costos de re-entrenamiento urgente

âœ… **Un modelo bien validado hoy = un modelo confiable maÃ±ana**

---

**Autor**: URLytics ML Team  
**Ãšltima actualizaciÃ³n**: 2025-11-15  
**VersiÃ³n**: 1.0
